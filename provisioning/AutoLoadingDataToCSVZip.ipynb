{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPi4bhpBqn8x"
   },
   "source": [
    "# Download this file on your local computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GrURFcNuV_DV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uXxXvIJ6qnCG"
   },
   "outputs": [],
   "source": [
    "def extract_station_info(data, node, prefix):\n",
    "  if node:\n",
    "    data[prefix + 'Code'].append(node.find('./ns1:StationCode', ns).text)\n",
    "    data[prefix + 'UIC'].append(int(node.find('./ns1:UICCode', ns).text))\n",
    "    data[prefix + 'Type'].append(int(node.find('./ns1:Type', ns).text))\n",
    "  else:\n",
    "    data[prefix + 'Code'].append(np.NaN)\n",
    "    data[prefix + 'UIC'].append(np.NaN)\n",
    "    data[prefix + 'Type'].append(np.NaN)\n",
    "\n",
    "def parse_timestamp(date_string):\n",
    "  return datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "def encode_list(nodes, sufix):\n",
    "  UIC_codes = [node.find(sufix, ns).text for node in nodes]\n",
    "  return ';'.join(UIC_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v7rUsNBxbJVS"
   },
   "outputs": [],
   "source": [
    "# namespace of the xml object\n",
    "ns={\n",
    "    'ns0': 'urn:ndov:cdm:trein:reisinformatie:messages:3',\n",
    "    'ns1': 'urn:ndov:cdm:trein:reisinformatie:data:2'\n",
    "}\n",
    "\n",
    "# dictionary that will save the data while loading it in\n",
    "data = {\n",
    "    # Ride\n",
    "    'RideId':[],\n",
    "    'RideTime': [],\n",
    "\n",
    "    # Departure station\n",
    "    'DepartureStationCode': [],\n",
    "    'DepartureStationUIC': [],\n",
    "    'DepartureStationType': [],\n",
    "\n",
    "    # Train\n",
    "    'TrainId': [],\n",
    "    'TrainType': [],\n",
    "    'TrainOperator': [],\n",
    "\n",
    "    # Planned destination\n",
    "    'PlannedDestinationStationCode': [],\n",
    "    'PlannedDestinationStationUIC': [],\n",
    "    'PlannedDestinationStationType': [],    \n",
    "\n",
    "    # Actual destination\n",
    "    'ActualDestinationStationCode': [],\n",
    "    'ActualDestinationStationUIC': [],\n",
    "    'ActualDestinationStationType': [],\n",
    "\n",
    "    # Departure times\n",
    "    'PlannedDepartureTime': [],\n",
    "    'ActualDepartureTime': [],\n",
    "    'ExactDepartureDelay': [],\n",
    "    'RoundedDepartureDelay': [],\n",
    "\n",
    "    # Departure platforms\n",
    "    'PlannedDeparturePlatform': [],\n",
    "    'ActualDeparturePlatform': [],\n",
    "\n",
    "    # Stop stations\n",
    "    'PlannedStopStations': [],\n",
    "    'ActualStopStations': [],\n",
    "\n",
    "    # Matirial type\n",
    "    'MaterialType': [],\n",
    "    'MaterialDesignation': [],\n",
    "    'MaterialLength': [],\n",
    "\n",
    "    # Change\n",
    "    'HasChange': [],\n",
    "    'ChangeType': [],\n",
    "\n",
    "    # Trip tip\n",
    "    'TripTipCode': [],\n",
    "    'TripTipStations' : [],\n",
    "\n",
    "    # Planned Shortened route\n",
    "    'PlannedShortenedStationCode': [],\n",
    "    'PlannedShortenedStationUIC': [],\n",
    "    'PlannedShortenedStationType': [],\n",
    "\n",
    "    # Actual Shortened route\n",
    "    'ActualShortenedStationCode': [],\n",
    "    'ActualShortenedStationUIC': [],\n",
    "    'ActualShortenedStationType': []\n",
    "}\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvV614tzWEv_",
    "outputId": "c89cfc93-570a-48bd-f26b-80377ea1c1f3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important to note is that the format is like: m/d/y \n",
    "month = np.array(pd.date_range(start='2016/1/1', end='2016/1/15').strftime('%Y-%m-%d'))\n",
    "month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBSuCEgmqnCJ"
   },
   "source": [
    "# Please keep in mind this is memory intensive good approach is to do each month seperately and later merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzKgbl6ZWGuj",
    "outputId": "998187e4-fbe1-4305-d4dd-fbbed9ddcc7d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "# loop through every day\r\n",
    "for day in month:\r\n",
    "    print(day) # this prints the day just to keep track where the program is at\r\n",
    "    df = pd.read_csv(f'https://trein.fwrite.org/AMS-Aurora-archive/{day[:7]}/DVS_{day}.csv.xz', header=None, names=['date', 'xml_obj', 'uuid'])\r\n",
    "    # loop through every entry of a day\r\n",
    "    for root_text in df['xml_obj'].values:  \r\n",
    "        root = ET.fromstring(root_text)\r\n",
    "\r\n",
    "        # Ride\r\n",
    "        ride = root.find('./ns1:ReisInformatieProductDVS/ns1:DynamischeVertrekStaat', ns)\r\n",
    "        data['RideId'].append(int(ride.find('ns1:RitId', ns).text))\r\n",
    "        date_string = root.find('./ns1:ReisInformatieProductDVS/ns1:RIPAdministratie/ns1:ReisInformatieTijdstip', ns).text\r\n",
    "        data['RideTime'].append(parse_timestamp(date_string))\r\n",
    "\r\n",
    "        # Train\r\n",
    "        train = ride.find('./ns1:Trein', ns)\r\n",
    "        \r\n",
    "        if not train: print('No Train, wtf?')\r\n",
    "        \r\n",
    "        data['TrainId'].append(train.find('./ns1:TreinNummer', ns).text)\r\n",
    "        data['TrainType'].append(train.find('./ns1:TreinSoort', ns).text)\r\n",
    "        data['TrainOperator'].append(train.find('./ns1:Vervoerder', ns).text)\r\n",
    "\r\n",
    "        # Planned destination\r\n",
    "        plannedDest = train.find('./ns1:TreinEindBestemming[@InfoStatus=\"Gepland\"]',ns)\r\n",
    "        extract_station_info(data, plannedDest, 'PlannedDestinationStation')\r\n",
    "\r\n",
    "        # Planned destination\r\n",
    "        actualDest = train.find('./ns1:TreinEindBestemming[@InfoStatus=\"Actueel\"]',ns)\r\n",
    "        extract_station_info(data, actualDest, 'ActualDestinationStation')\r\n",
    "\r\n",
    "        # Departure station\r\n",
    "        extract_station_info(data,ride.find('./ns1:RitStation', ns), 'DepartureStation')\r\n",
    "\r\n",
    "        data['PlannedDeparturePlatform'].append(int(train.find('./ns1:TreinVertrekSpoor[@InfoStatus=\"Gepland\"]/ns1:SpoorNummer', ns).text))\r\n",
    "        data['ActualDeparturePlatform'].append(int(train.find('./ns1:TreinVertrekSpoor[@InfoStatus=\"Actueel\"]/ns1:SpoorNummer', ns).text))\r\n",
    "\r\n",
    "        # Departure times\r\n",
    "        date_string = train.find('./ns1:VertrekTijd[@InfoStatus=\"Gepland\"]', ns).text\r\n",
    "        data['PlannedDepartureTime'].append(parse_timestamp(date_string))\r\n",
    "\r\n",
    "        date_string = train.find('./ns1:VertrekTijd[@InfoStatus=\"Actueel\"]', ns).text\r\n",
    "        data['ActualDepartureTime'].append(parse_timestamp(date_string))\r\n",
    "\r\n",
    "        data['ExactDepartureDelay'].append(train.find('./ns1:ExacteVertrekVertraging', ns).text)\r\n",
    "        data['RoundedDepartureDelay'].append(train.find('./ns1:GedempteVertrekVertraging', ns).text)\r\n",
    "\r\n",
    "        # Stop stations\r\n",
    "        wagons = train.find('./ns1:TreinVleugel', ns)\r\n",
    "        if not wagons: print('No wagons, wtf?')\r\n",
    "        stop_stations = wagons.findall('./ns1:StopStations[@InfoStatus=\"Gepland\"]/ns1:Station', ns)\r\n",
    "        if not stop_stations: print('No stop_stations, wtf?')\r\n",
    "\r\n",
    "        data['PlannedStopStations'].append(encode_list(stop_stations, './ns1:UICCode'))\r\n",
    "\r\n",
    "        stop_stations = wagons.findall('./ns1:StopStations[@InfoStatus=\"Actueel\"]/ns1:Station', ns)\r\n",
    "        data['ActualStopStations'].append(encode_list(stop_stations, './ns1:UICCode'))\r\n",
    "        if not stop_stations: print('No stop_stations2, wtf?')\r\n",
    "\r\n",
    "        # Material\r\n",
    "        material = wagons.find('./ns1:MaterieelDeelDVS', ns)\r\n",
    "        if material:\r\n",
    "            data['MaterialType'].append(material.find('./ns1:MaterieelSoort', ns).text)\r\n",
    "            data['MaterialDesignation'].append(material.find('./ns1:MaterieelAanduiding', ns).text)\r\n",
    "            data['MaterialLength'].append(material.find('./ns1:MaterieelLengte', ns).text)\r\n",
    "        else:\r\n",
    "            data['MaterialType'].append(np.NaN)\r\n",
    "            data['MaterialDesignation'].append(np.NaN)\r\n",
    "            data['MaterialLength'].append(np.NaN)\r\n",
    "\r\n",
    "        # Change\r\n",
    "        changes = root.findall('.//ns1:Wijziging', ns)\r\n",
    "        if changes:\r\n",
    "            data['HasChange'].append(True)\r\n",
    "            data['ChangeType'].append(encode_list(changes, './ns1:WijzigingType'))\r\n",
    "        else:\r\n",
    "            data['HasChange'].append(False)\r\n",
    "            data['ChangeType'].append(np.NaN)\r\n",
    "\r\n",
    "        # Trip tip\r\n",
    "        tip = train.find('./ns1:ReisTip', ns)\r\n",
    "        if tip:\r\n",
    "            data['TripTipCode'].append(tip.find('./ns1:ReisTipCode', ns).text)\r\n",
    "            data['TripTipStations'].append(encode_list(tip.findall('./ns1:ReisTipStation', ns), './ns1:UICCode'))\r\n",
    "        else:\r\n",
    "            data['TripTipCode'].append(np.NaN)\r\n",
    "            data['TripTipStations'].append(np.NaN)\r\n",
    "\r\n",
    "        # Shortened route\r\n",
    "        plannedShort = train.find('./ns1:VerkorteRoute[@InfoStatus=\"Gepland\"]', ns)\r\n",
    "        if plannedShort:\r\n",
    "            extract_station_info(data, plannedDest, 'PlannedShortenedStation')\r\n",
    "        else:\r\n",
    "            extract_station_info(data, None, 'PlannedShortenedStation')\r\n",
    "\r\n",
    "        actualShort = train.find('./ns1:VerkorteRoute[@InfoStatus=\"Actueel\"]', ns)\r\n",
    "        if actualShort:\r\n",
    "            extract_station_info(data, plannedDest, 'ActualShortenedStation')\r\n",
    "        else:\r\n",
    "            extract_station_info(data, None, 'ActualShortenedStation')\r\n",
    "            \r\n",
    "# Convert the dictionary to a dataframe\r\n",
    "df_flat = pd.DataFrame(data)    \r\n",
    "print(df_flat.shape) # show the file size kinda\r\n",
    "# save the file, specify your path and name for the file\r\n",
    "df_flat.to_csv('./data/september.csv.zip', \r\n",
    "               index=False, \r\n",
    "               compression=dict(method='zip', archive_name='january.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsrk1mUwqnCM",
    "outputId": "36854ebe-07cb-4ecd-b9ec-d9823bfaeffa"
   },
   "outputs": [],
   "source": [
    "# you can laod the files again in \r\n",
    "df_july = pd.read_csv('../data/july.csv.zip')\r\n",
    "df_august = pd.read_csv('../data/august.csv.zip')\r\n",
    "df_september = pd.read_csv('../data/september.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmkBFh4tqnCQ"
   },
   "outputs": [],
   "source": [
    "# here you merge them into one big dataframe\n",
    "months = [df_july, df_august, df_september]\n",
    "df_months = pd.concat(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXwV3KZFqnCR"
   },
   "outputs": [],
   "source": [
    "# save the big dataframe again\n",
    "df_months.to_csv('../data/july_to_september.csv.zip', \n",
    "                 index=False, \n",
    "                 compression=dict(method='zip', archive_name='july_to_september.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQIa0u97qnCV"
   },
   "outputs": [],
   "source": [
    "# here we filter out only all rides from utrecht to amsterdam and vise versa\n",
    "df_ut_asd = df_months.loc[((df_months['DepartureStationCode'] == 'UT') & \n",
    "               (df_months['PlannedDestinationStationCode'] == 'ASD')) | \n",
    "              ((df_months['DepartureStationCode'] == 'ASD') & \n",
    "               (df_months['PlannedDestinationStationCode'] == 'UT'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2wgSTEfqnCW"
   },
   "outputs": [],
   "source": [
    "# save the reduced dataframe again\n",
    "df_ut_asd.to_csv('../data/july_to_september_utrecht_amsterdam.csv.zip', \n",
    "                 index=False, \n",
    "                 compression=dict(method='zip', archive_name='july_to_september_utrecht_amsterdam.csv'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoLoadingDataToCSVZip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python382jvsc74a57bd0b484e608f6e9819578ec834ce331f788e59296a3ef9763dbfaaa1081558300ba"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}