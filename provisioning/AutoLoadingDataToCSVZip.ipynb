{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPi4bhpBqn8x"
   },
   "source": [
    "# Download this file on your local computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GrURFcNuV_DV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from datetime import datetime \n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uXxXvIJ6qnCG"
   },
   "outputs": [],
   "source": [
    "def extract_station_info(data, node, prefix):\n",
    "  if node:\n",
    "    data[prefix + 'Code'].append(node.find('./ns2:StationCode', ns).text)\n",
    "    data[prefix + 'UIC'].append(int(node.find('./ns2:UICCode', ns).text))\n",
    "    data[prefix + 'Type'].append(int(node.find('./ns2:Type', ns).text))\n",
    "  else:\n",
    "    data[prefix + 'Code'].append(np.NaN)\n",
    "    data[prefix + 'UIC'].append(np.NaN)\n",
    "    data[prefix + 'Type'].append(np.NaN)\n",
    "\n",
    "def parse_timestamp(date_string):\n",
    "  return datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "def encode_list(nodes, sufix):\n",
    "  UIC_codes = [node.find(sufix, ns).text for node in nodes]\n",
    "  return ';'.join(UIC_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "v7rUsNBxbJVS"
   },
   "outputs": [],
   "source": [
    "# namespace of the xml object\n",
    "ns={\n",
    "    'ns1d': 'urn:ndov:cdm:trein:reisinformatie:messages:5',\n",
    "    'ns1a': 'urn:ndov:cdm:trein:reisinformatie:messages:dynamischeaankomststaat:1',\n",
    "    'ns2': 'urn:ndov:cdm:trein:reisinformatie:data:4',\n",
    "}\n",
    "\n",
    "# dictionary that will save the data while loading it in\n",
    "def arrival_data_template():\n",
    "\n",
    "    return {\n",
    "        'ObservationTime': [],\n",
    "\n",
    "        # Ride\n",
    "        'RideId':[],\n",
    "        'RideTime': [],\n",
    "\n",
    "        # Departure station\n",
    "        'DepartureStationCode': [],\n",
    "        'DepartureStationUIC': [],\n",
    "        'DepartureStationType': [],\n",
    "\n",
    "        # Train\n",
    "        'TrainId': [],\n",
    "        'TrainType': [],\n",
    "        'TrainOperator': [],\n",
    "\n",
    "        # Actual destination\n",
    "        'DestinationStationCode': [],\n",
    "        'DestinationStationUIC': [],\n",
    "        'DestinationStationType': [],\n",
    "\n",
    "        # Arrival times\n",
    "        'PlannedArrivalTime': [],\n",
    "        'ActualArrivalTime': [],\n",
    "\n",
    "        # Arrival platform\n",
    "        'PlannedArrivalPlatform': [],\n",
    "        'PlannedArrivalPlatformSuffix': [],\n",
    "        'ActualArrivalPlatform': [],\n",
    "        'ActualArrivalPlatformSuffix': [],\n",
    "\n",
    "#         # Departure platforms\n",
    "#         'PlannedDeparturePlatform': [],\n",
    "#         'ActualDeparturePlatform': [],\n",
    "\n",
    "#         # Stop stations\n",
    "#         'PlannedStopStations': [],\n",
    "#         'ActualStopStations': [],\n",
    "\n",
    "#         # Matirial type\n",
    "#         'MaterialType': [],\n",
    "#         'MaterialDesignation': [],\n",
    "#         'MaterialLength': [],\n",
    "\n",
    "#         'ChangeType': [],\n",
    "\n",
    "    }\n",
    "\n",
    "def departure_data_template():\n",
    "    return {\n",
    "    'ObservationTime': [],\n",
    "\n",
    "    # Ride\n",
    "    'RideId':[],\n",
    "    'RideTime': [],\n",
    "\n",
    "    # Departure station\n",
    "    'DepartureStationCode': [],\n",
    "    'DepartureStationUIC': [],\n",
    "    'DepartureStationType': [],\n",
    "\n",
    "    # Train\n",
    "    'TrainId': [],\n",
    "    'TrainType': [],\n",
    "    'TrainOperator': [],\n",
    "\n",
    "    # Actual destination\n",
    "    'DestinationStationCode': [],\n",
    "    'DestinationStationUIC': [],\n",
    "    'DestinationStationType': [],\n",
    "\n",
    "    # Departure times\n",
    "    'PlannedDepartureTime': [],\n",
    "    'ActualDepartureTime': [],\n",
    "\n",
    "    # Departure platform\n",
    "    'PlannedDeparturePlatform': [],\n",
    "    'PlannedDeparturePlatformSuffix': [],\n",
    "    'ActualDeparturePlatform': [],\n",
    "    'ActualDeparturePlatformSuffix': [],\n",
    "\n",
    "    # Departure platforms\n",
    "    'PlannedDeparturePlatform': [],\n",
    "    'ActualDeparturePlatform': [],\n",
    "\n",
    "    # Stop stations\n",
    "    'PlannedStopStations': [],\n",
    "    'ActualStopStations': [],\n",
    "\n",
    "    # Matirial type\n",
    "    'MaterialType': [],\n",
    "    'MaterialDesignation': [],\n",
    "    'MaterialLength': [],\n",
    "    \n",
    "    'HasChange': [],\n",
    "    'ChangeType': [],\n",
    "\n",
    "}\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvV614tzWEv_",
    "outputId": "c89cfc93-570a-48bd-f26b-80377ea1c1f3",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_amsterdam = b'<ns2:RitStation><ns2:StationCode>ASD</ns2:StationCode>'\n",
    "station_utrecht = b'<ns2:RitStation><ns2:StationCode>UT</ns2:StationCode>'\n",
    "source_amsterdam = b'<ns2:TreinHerkomst InfoStatus=\"\"Gepland\"\"><ns2:StationCode>ASD</ns2:StationCode'\n",
    "source_utrecht = b'<ns2:TreinHerkomst InfoStatus=\"\"Gepland\"\"><ns2:StationCode>UT</ns2:StationCode>'\n",
    "destination_amsterdam = b'<ns2:TreinEindBestemming InfoStatus=\"\"Gepland\"\"><ns2:StationCode>AMS</ns2:StationCode>'\n",
    "destination_utrecht = b'<ns2:TreinEindBestemming InfoStatus=\"\"Gepland\"\"><ns2:StationCode>UT</ns2:StationCode>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-12-01' '2019-12-02' '2019-12-03' '2019-12-04' '2019-12-05'\n",
      " '2019-12-06' '2019-12-07' '2019-12-08' '2019-12-09' '2019-12-10'\n",
      " '2019-12-11' '2019-12-12' '2019-12-13' '2019-12-14' '2019-12-15'\n",
      " '2019-12-16' '2019-12-17' '2019-12-18' '2019-12-19' '2019-12-20'\n",
      " '2019-12-21' '2019-12-22' '2019-12-23' '2019-12-24' '2019-12-25'\n",
      " '2019-12-26' '2019-12-27' '2019-12-28' '2019-12-29' '2019-12-30'\n",
      " '2019-12-31']\n",
      "downloading:  2019-12-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bd92cd558b98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlzma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLZMAFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource_utrecht\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstation_amsterdam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource_amsterdam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstation_utrecht\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0marrival_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\lzma.py\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\_compression.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneeds_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                     \u001b[0mrawblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBUFFER_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrawblock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                         raise EOFError(\"Compressed file ended before the \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\response.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    516\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mb\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m                 if (\n\u001b[0;32m    520\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "\n",
    "arrival_lines = []\n",
    "departure_lines = []\n",
    "\n",
    "parsing_days = pd.date_range(start='2019/12/1', end='2019/12/31').strftime('%Y-%m-%d').values\n",
    "print(parsing_days)\n",
    "\n",
    "for day in parsing_days:\n",
    "    print('downloading: ',day) \n",
    "    url = f'https://trein.fwrite.org/AMS-Aurora-archive/{day[:7]}/DVSPPV_{day}.csv.xz'\n",
    "\n",
    "    req = requests.get(url, stream=True)\n",
    "\n",
    "    with lzma.LZMAFile(req.raw) as file:\n",
    "        for line in file:\n",
    "            if (source_utrecht in line and station_amsterdam in line) or (source_amsterdam in line and station_utrecht in line) :\n",
    "                arrival_lines.append(line)\n",
    "            if (station_amsterdam in line and destination_utrecht in line) or (station_utrecht in line and destination_amsterdam in line) :\n",
    "                departure_lines.append(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "df_arrivals = pd.read_csv(StringIO(b'\\n'.join(arrival_lines).decode('utf-8')), header=None, names=['date', 'xml_obj', 'uuid'])\n",
    "df_departures = pd.read_csv(StringIO(b'\\n'.join(departure_lines).decode('utf-8')), header=None, names=['date', 'xml_obj', 'uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departures.to_csv('2019-12-01--2019-12-31-departures.csv', index=None)\n",
    "df_arrivals.to_csv('2019-12-01--2019-12-31-arrivals.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBSuCEgmqnCJ"
   },
   "source": [
    "# Please keep in mind this is memory intensive good approach is to do each month seperately and later merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa_temp = pd.read_csv('../assets/data/2019 UT-ASD/2019-01-01--2019-03-31 arrivals.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzKgbl6ZWGuj",
    "outputId": "998187e4-fbe1-4305-d4dd-fbbed9ddcc7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7146, 18)\n"
     ]
    }
   ],
   "source": [
    "arrival_data = arrival_data_template()\n",
    "\n",
    "# loop through every day\n",
    "\n",
    "for root_text, observation_time in dfa_temp[['xml_obj', 'date']].values:  \n",
    "            \n",
    "    arrival_data['ObservationTime'].append(observation_time)\n",
    "\n",
    "    root = ET.fromstring(root_text)\n",
    "\n",
    "    # Ride\n",
    "    ride = root.find('./ns2:ReisInformatieProductDAS/ns2:DynamischeAankomstStaat', ns)\n",
    "\n",
    "    arrival_data['RideId'].append(int(ride.find('./ns2:RitId', ns).text))\n",
    "    arrival_data['RideTime'].append(root.find('./ns2:ReisInformatieProductDAS/ns2:RIPAdministratie/ns2:ReisInformatieTijdstip', ns).text)\n",
    "\n",
    "    # Stations\n",
    "    train = ride.find('./ns2:TreinAankomst', ns)\n",
    "\n",
    "    destinationStation = ride.find('./ns2:RitStation', ns)\n",
    "    departureStation = train.find('./ns2:TreinHerkomst[@InfoStatus=\"Gepland\"]',ns)\n",
    "    \n",
    "    extract_station_info(arrival_data, departureStation, 'DepartureStation')\n",
    "    extract_station_info(arrival_data, destinationStation, 'DestinationStation')\n",
    "\n",
    "    # Arrival times\n",
    "    arrival_data['ActualArrivalTime'].append(train.find('./ns2:AankomstTijd[@InfoStatus=\"Actueel\"]', ns).text)\n",
    "    arrival_data['PlannedArrivalTime'].append(train.find('./ns2:AankomstTijd[@InfoStatus=\"Gepland\"]', ns).text)\n",
    "    \n",
    "    # Train\n",
    "    arrival_data['TrainId'].append(train.find('./ns2:TreinNummer', ns).text)\n",
    "    arrival_data['TrainType'].append(train.find('./ns2:TreinSoort', ns).text)\n",
    "    arrival_data['TrainOperator'].append(train.find('./ns2:Vervoerder', ns).text)\n",
    "\n",
    "    arrival_data['PlannedArrivalPlatform'].append(train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorNummer', ns).text)\n",
    "    suffix = train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorFase', ns)\n",
    "    arrival_data['PlannedArrivalPlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "\n",
    "    arrival_data['ActualArrivalPlatform'].append(train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorNummer', ns).text)\n",
    "    suffix = train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorFase', ns)\n",
    "    arrival_data['ActualArrivalPlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "    \n",
    "# Convert the dictionary to a dataframe\n",
    "dfa = pd.DataFrame(arrival_data)    \n",
    "print(dfa.shape) # show the file size kinda\n",
    "# # save the file, specify your path and name for the file\n",
    "# df_flat.to_csv('./data/september.csv.zip', \n",
    "#                index=False, \n",
    "#                compression=dict(method='zip', archive_name='january.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfd_temp = pd.read_csv('../assets/data/2019 UT-ASD/2019-01-01--2019-03-31 departures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7146, 18)\n"
     ]
    }
   ],
   "source": [
    "departure_data = departure_data_template()\n",
    "# Parse records about departures\n",
    "for root_text, observation_time in dfd_temp[['xml_obj', 'date']].values:  \n",
    "\n",
    "    departure_data['ObservationTime'].append(observation_time)\n",
    "\n",
    "    root = ET.fromstring(root_text)\n",
    "\n",
    "    # Ride\n",
    "    ride = root.find('./ns2:ReisInformatieProductDVS/ns2:DynamischeVertrekStaat', ns)\n",
    "\n",
    "    departure_data['RideId'].append(int(ride.find('./ns2:RitId', ns).text))\n",
    "    departure_data['RideTime'].append(root.find('./ns2:ReisInformatieProductDVS/ns2:RIPAdministratie/ns2:ReisInformatieTijdstip', ns).text)\n",
    "\n",
    "    # Stations\n",
    "    train = ride.find('./ns2:Trein', ns)\n",
    "\n",
    "    departureStation = ride.find('./ns2:RitStation', ns)\n",
    "    destinationStation = train.find('./ns2:TreinEindBestemming[@InfoStatus=\"Gepland\"]',ns)\n",
    "    \n",
    "    extract_station_info(departure_data, departureStation, 'DepartureStation')\n",
    "    extract_station_info(departure_data, destinationStation, 'DestinationStation')\n",
    "\n",
    "    # Departure times\n",
    "    departure_data['ActualDepartureTime'].append(train.find('./ns2:VertrekTijd[@InfoStatus=\"Actueel\"]', ns).text)\n",
    "    departure_data['PlannedDepartureTime'].append(train.find('./ns2:VertrekTijd[@InfoStatus=\"Gepland\"]', ns).text)\n",
    "    \n",
    "    # Train\n",
    "    departure_data['TrainId'].append(train.find('./ns2:TreinNummer', ns).text)\n",
    "    departure_data['TrainType'].append(train.find('./ns2:TreinSoort', ns).text)\n",
    "    departure_data['TrainOperator'].append(train.find('./ns2:Vervoerder', ns).text)\n",
    "    \n",
    "    platform_planned = train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Gepland\"]', ns)\n",
    "    platform_actual = train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Actueel\"]', ns)\n",
    "    \n",
    "    if platform_planned and platform_actual:   \n",
    "        departure_data['PlannedDeparturePlatform'].append(train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorNummer', ns).text)\n",
    "        suffix = train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorFase', ns)\n",
    "        departure_data['PlannedDeparturePlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "\n",
    "        departure_data['ActualDeparturePlatform'].append(train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorNummer', ns).text)\n",
    "        suffix = train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorFase', ns)\n",
    "        departure_data['ActualDeparturePlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "    else:\n",
    "        departure_data['PlannedDeparturePlatform'].append(None)\n",
    "        suffix = None\n",
    "        departure_data['PlannedDeparturePlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "\n",
    "        departure_data['ActualDeparturePlatform'].append(None)\n",
    "        suffix = None\n",
    "        departure_data['ActualDeparturePlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "    \n",
    "    # Stop stations\n",
    "    wagons = train.find('./ns2:TreinVleugel', ns)\n",
    "    if not wagons: print('No wagons, wtf?')\n",
    "    stop_stations = wagons.findall('./ns2:StopStations[@InfoStatus=\"Gepland\"]/ns2:Station', ns)\n",
    "    if not stop_stations: print('No stop_stations, wtf?')\n",
    "\n",
    "    departure_data['PlannedStopStations'].append(encode_list(stop_stations, './ns2:UICCode'))\n",
    "\n",
    "    stop_stations = wagons.findall('./ns2:StopStations[@InfoStatus=\"Actueel\"]/ns2:Station', ns)\n",
    "    departure_data['ActualStopStations'].append(encode_list(stop_stations, './ns2:UICCode'))\n",
    "    if not stop_stations: print('No stop_stations2, wtf?')\n",
    "\n",
    "    # Material\n",
    "    material = wagons.find('./ns2:MaterieelDeelDVS', ns)\n",
    "    if material:\n",
    "        departure_data['MaterialType'].append(material.find('./ns2:MaterieelSoort', ns).text)\n",
    "        departure_data['MaterialDesignation'].append(material.find('./ns2:MaterieelAanduiding', ns).text)\n",
    "        departure_data['MaterialLength'].append(material.find('./ns2:MaterieelLengte', ns).text)\n",
    "    else:\n",
    "        departure_data['MaterialType'].append(np.NaN)\n",
    "        departure_data['MaterialDesignation'].append(np.NaN)\n",
    "        departure_data['MaterialLength'].append(np.NaN)\n",
    "\n",
    "    # Change\n",
    "    changes = root.findall('./ns2:Wijziging', ns)\n",
    "    if changes:\n",
    "        departure_data['HasChange'].append(True)\n",
    "        departure_data['ChangeType'].append(encode_list(changes, './ns2:WijzigingType'))\n",
    "    else:\n",
    "        departure_data['HasChange'].append(False)\n",
    "        departure_data['ChangeType'].append(np.NaN)\n",
    "        \n",
    "dfd = pd.DataFrame(departure_data)  \n",
    "print(dfa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfa.value_counts('RideId', 'Planned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RideInstance</th>\n",
       "      <th>ObservationTime</th>\n",
       "      <th>RideId</th>\n",
       "      <th>RideTime</th>\n",
       "      <th>DepartureStationCode</th>\n",
       "      <th>DepartureStationUIC</th>\n",
       "      <th>DepartureStationType</th>\n",
       "      <th>TrainId</th>\n",
       "      <th>TrainType</th>\n",
       "      <th>TrainOperator</th>\n",
       "      <th>DestinationStationCode</th>\n",
       "      <th>DestinationStationUIC</th>\n",
       "      <th>DestinationStationType</th>\n",
       "      <th>PlannedDepartureTime</th>\n",
       "      <th>ActualDepartureTime</th>\n",
       "      <th>PlannedDeparturePlatform</th>\n",
       "      <th>PlannedDeparturePlatformSuffix</th>\n",
       "      <th>ActualDeparturePlatform</th>\n",
       "      <th>ActualDeparturePlatformSuffix</th>\n",
       "      <th>PlannedStopStations</th>\n",
       "      <th>ActualStopStations</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>MaterialDesignation</th>\n",
       "      <th>MaterialLength</th>\n",
       "      <th>HasChange</th>\n",
       "      <th>ChangeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1402#2019-01-01T00:18:00.000Z</td>\n",
       "      <td>2019-01-01 01:18:41.841361+01:00</td>\n",
       "      <td>1402</td>\n",
       "      <td>2019-01-01T00:18:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1402</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01T00:18:00.000Z</td>\n",
       "      <td>2019-01-01T00:18:00.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>8400074;8400621</td>\n",
       "      <td>8400074;8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>6</td>\n",
       "      <td>16210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1406#2019-01-01T01:19:00.000Z</td>\n",
       "      <td>2019-01-01 02:21:06.626009+01:00</td>\n",
       "      <td>1406</td>\n",
       "      <td>2019-01-01T01:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1406</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01T01:19:00.000Z</td>\n",
       "      <td>2019-01-01T01:20:16.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>4</td>\n",
       "      <td>10860</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1410#2019-01-01T02:19:00.000Z</td>\n",
       "      <td>2019-01-01 03:20:25.483579+01:00</td>\n",
       "      <td>1410</td>\n",
       "      <td>2019-01-01T02:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1410</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01T02:19:00.000Z</td>\n",
       "      <td>2019-01-01T02:19:00.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>6</td>\n",
       "      <td>16210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1414#2019-01-01T03:19:00.000Z</td>\n",
       "      <td>2019-01-01 04:19:50.604934+01:00</td>\n",
       "      <td>1414</td>\n",
       "      <td>2019-01-01T03:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1414</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01T03:19:00.000Z</td>\n",
       "      <td>2019-01-01T03:19:00.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>4</td>\n",
       "      <td>10860</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1418#2019-01-01T04:19:00.000Z</td>\n",
       "      <td>2019-01-01 05:19:47.184006+01:00</td>\n",
       "      <td>1418</td>\n",
       "      <td>2019-01-01T04:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1418</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-01-01T04:19:00.000Z</td>\n",
       "      <td>2019-01-01T04:19:00.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>4</td>\n",
       "      <td>10860</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>1418#2019-03-31T03:19:00.000Z</td>\n",
       "      <td>2019-03-31 05:19:17.560193+02:00</td>\n",
       "      <td>1418</td>\n",
       "      <td>2019-03-31T03:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1418</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-31T03:19:00.000Z</td>\n",
       "      <td>2019-03-31T03:19:00.000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>4</td>\n",
       "      <td>10860</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>1422#2019-03-31T04:25:00.000Z</td>\n",
       "      <td>2019-03-31 06:25:39.590373+02:00</td>\n",
       "      <td>1422</td>\n",
       "      <td>2019-03-31T04:25:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1422</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-31T04:25:00.000Z</td>\n",
       "      <td>2019-03-31T04:25:00.000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>6</td>\n",
       "      <td>16210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3352</th>\n",
       "      <td>7393#2019-03-31T22:28:00.000Z</td>\n",
       "      <td>2019-03-31 23:18:05.176728+02:00</td>\n",
       "      <td>7393</td>\n",
       "      <td>2019-03-31T22:28:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>7393</td>\n",
       "      <td>Sprinter</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-31T22:28:00.000Z</td>\n",
       "      <td>2019-03-31T22:28:00.000Z</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>7</td>\n",
       "      <td>b</td>\n",
       "      <td>8400060;8400057;8400194;8400074;8400231;840004...</td>\n",
       "      <td>8400060;8400057;8400194;8400074;8400231;840004...</td>\n",
       "      <td>SLT</td>\n",
       "      <td>6</td>\n",
       "      <td>10050</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3354</th>\n",
       "      <td>7395#2019-03-31T22:57:00.000Z</td>\n",
       "      <td>2019-03-31 23:47:04.005991+02:00</td>\n",
       "      <td>7395</td>\n",
       "      <td>2019-03-31T22:57:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>7395</td>\n",
       "      <td>Sprinter</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-31T22:57:00.000Z</td>\n",
       "      <td>2019-03-31T22:57:00.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8400060;8400057;8400194;8400074;8400231;840004...</td>\n",
       "      <td>8400060;8400057;8400194;8400074;8400231;840004...</td>\n",
       "      <td>SLT</td>\n",
       "      <td>6</td>\n",
       "      <td>10050</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>3089#2019-03-31T21:54:00.000Z</td>\n",
       "      <td>2019-03-31 23:54:26.257492+02:00</td>\n",
       "      <td>3089</td>\n",
       "      <td>2019-03-31T21:54:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>3089</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-31T21:54:00.000Z</td>\n",
       "      <td>2019-03-31T21:54:00.000Z</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>8400057;8400621</td>\n",
       "      <td>8400057;8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>4</td>\n",
       "      <td>10860</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>954 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       RideInstance                   ObservationTime  RideId  \\\n",
       "2     1402#2019-01-01T00:18:00.000Z  2019-01-01 01:18:41.841361+01:00    1402   \n",
       "8     1406#2019-01-01T01:19:00.000Z  2019-01-01 02:21:06.626009+01:00    1406   \n",
       "11    1410#2019-01-01T02:19:00.000Z  2019-01-01 03:20:25.483579+01:00    1410   \n",
       "14    1414#2019-01-01T03:19:00.000Z  2019-01-01 04:19:50.604934+01:00    1414   \n",
       "17    1418#2019-01-01T04:19:00.000Z  2019-01-01 05:19:47.184006+01:00    1418   \n",
       "...                             ...                               ...     ...   \n",
       "3348  1418#2019-03-31T03:19:00.000Z  2019-03-31 05:19:17.560193+02:00    1418   \n",
       "3350  1422#2019-03-31T04:25:00.000Z  2019-03-31 06:25:39.590373+02:00    1422   \n",
       "3352  7393#2019-03-31T22:28:00.000Z  2019-03-31 23:18:05.176728+02:00    7393   \n",
       "3354  7395#2019-03-31T22:57:00.000Z  2019-03-31 23:47:04.005991+02:00    7395   \n",
       "3355  3089#2019-03-31T21:54:00.000Z  2019-03-31 23:54:26.257492+02:00    3089   \n",
       "\n",
       "                      RideTime DepartureStationCode  DepartureStationUIC  \\\n",
       "2     2019-01-01T00:18:00.000Z                  ASD              8400058   \n",
       "8     2019-01-01T01:19:00.000Z                  ASD              8400058   \n",
       "11    2019-01-01T02:19:00.000Z                  ASD              8400058   \n",
       "14    2019-01-01T03:19:00.000Z                  ASD              8400058   \n",
       "17    2019-01-01T04:19:00.000Z                  ASD              8400058   \n",
       "...                        ...                  ...                  ...   \n",
       "3348  2019-03-31T03:19:00.000Z                  ASD              8400058   \n",
       "3350  2019-03-31T04:25:00.000Z                  ASD              8400058   \n",
       "3352  2019-03-31T22:28:00.000Z                  ASD              8400058   \n",
       "3354  2019-03-31T22:57:00.000Z                  ASD              8400058   \n",
       "3355  2019-03-31T21:54:00.000Z                  ASD              8400058   \n",
       "\n",
       "      DepartureStationType TrainId  TrainType TrainOperator  \\\n",
       "2                        6    1402  Intercity            NS   \n",
       "8                        6    1406  Intercity            NS   \n",
       "11                       6    1410  Intercity            NS   \n",
       "14                       6    1414  Intercity            NS   \n",
       "17                       6    1418  Intercity            NS   \n",
       "...                    ...     ...        ...           ...   \n",
       "3348                     6    1418  Intercity            NS   \n",
       "3350                     6    1422  Intercity            NS   \n",
       "3352                     6    7393   Sprinter            NS   \n",
       "3354                     6    7395   Sprinter            NS   \n",
       "3355                     6    3089  Intercity            NS   \n",
       "\n",
       "     DestinationStationCode  DestinationStationUIC  DestinationStationType  \\\n",
       "2                        UT                8400621                       6   \n",
       "8                        UT                8400621                       6   \n",
       "11                       UT                8400621                       6   \n",
       "14                       UT                8400621                       6   \n",
       "17                       UT                8400621                       6   \n",
       "...                     ...                    ...                     ...   \n",
       "3348                     UT                8400621                       6   \n",
       "3350                     UT                8400621                       6   \n",
       "3352                     UT                8400621                       6   \n",
       "3354                     UT                8400621                       6   \n",
       "3355                     UT                8400621                       6   \n",
       "\n",
       "          PlannedDepartureTime       ActualDepartureTime  \\\n",
       "2     2019-01-01T00:18:00.000Z  2019-01-01T00:18:00.000Z   \n",
       "8     2019-01-01T01:19:00.000Z  2019-01-01T01:20:16.000Z   \n",
       "11    2019-01-01T02:19:00.000Z  2019-01-01T02:19:00.000Z   \n",
       "14    2019-01-01T03:19:00.000Z  2019-01-01T03:19:00.000Z   \n",
       "17    2019-01-01T04:19:00.000Z  2019-01-01T04:19:00.000Z   \n",
       "...                        ...                       ...   \n",
       "3348  2019-03-31T03:19:00.000Z  2019-03-31T03:19:00.000Z   \n",
       "3350  2019-03-31T04:25:00.000Z  2019-03-31T04:25:00.000Z   \n",
       "3352  2019-03-31T22:28:00.000Z  2019-03-31T22:28:00.000Z   \n",
       "3354  2019-03-31T22:57:00.000Z  2019-03-31T22:57:00.000Z   \n",
       "3355  2019-03-31T21:54:00.000Z  2019-03-31T21:54:00.000Z   \n",
       "\n",
       "     PlannedDeparturePlatform PlannedDeparturePlatformSuffix  \\\n",
       "2                           2                              b   \n",
       "8                           2                              b   \n",
       "11                          2                              b   \n",
       "14                          2                              b   \n",
       "17                          2                              b   \n",
       "...                       ...                            ...   \n",
       "3348                        7                              a   \n",
       "3350                        7                              b   \n",
       "3352                        7                              b   \n",
       "3354                        2                              b   \n",
       "3355                        2                              b   \n",
       "\n",
       "     ActualDeparturePlatform ActualDeparturePlatformSuffix  \\\n",
       "2                          2                          None   \n",
       "8                          2                             b   \n",
       "11                         2                             b   \n",
       "14                         2                             b   \n",
       "17                         2                             b   \n",
       "...                      ...                           ...   \n",
       "3348                       7                             a   \n",
       "3350                       7                             b   \n",
       "3352                       7                             b   \n",
       "3354                       2                             b   \n",
       "3355                       2                             b   \n",
       "\n",
       "                                    PlannedStopStations  \\\n",
       "2                                       8400074;8400621   \n",
       "8                                               8400621   \n",
       "11                                              8400621   \n",
       "14                                              8400621   \n",
       "17                                              8400621   \n",
       "...                                                 ...   \n",
       "3348                                            8400621   \n",
       "3350                                            8400621   \n",
       "3352  8400060;8400057;8400194;8400074;8400231;840004...   \n",
       "3354  8400060;8400057;8400194;8400074;8400231;840004...   \n",
       "3355                                    8400057;8400621   \n",
       "\n",
       "                                     ActualStopStations MaterialType  \\\n",
       "2                                       8400074;8400621         VIRM   \n",
       "8                                               8400621         VIRM   \n",
       "11                                              8400621         VIRM   \n",
       "14                                              8400621         VIRM   \n",
       "17                                              8400621         VIRM   \n",
       "...                                                 ...          ...   \n",
       "3348                                            8400621         VIRM   \n",
       "3350                                            8400621         VIRM   \n",
       "3352  8400060;8400057;8400194;8400074;8400231;840004...          SLT   \n",
       "3354  8400060;8400057;8400194;8400074;8400231;840004...          SLT   \n",
       "3355                                    8400057;8400621         VIRM   \n",
       "\n",
       "     MaterialDesignation MaterialLength  HasChange  ChangeType  \n",
       "2                      6          16210      False         NaN  \n",
       "8                      4          10860      False         NaN  \n",
       "11                     6          16210      False         NaN  \n",
       "14                     4          10860      False         NaN  \n",
       "17                     4          10860      False         NaN  \n",
       "...                  ...            ...        ...         ...  \n",
       "3348                   4          10860      False         NaN  \n",
       "3350                   6          16210      False         NaN  \n",
       "3352                   6          10050      False         NaN  \n",
       "3354                   6          10050      False         NaN  \n",
       "3355                   4          10860      False         NaN  \n",
       "\n",
       "[954 rows x 26 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'RideInstance' in dfd:\n",
    "    del dfd['RideInstance']\n",
    "dfd.insert(0, 'RideInstance', dfd.RideId.astype(str) + '#' + dfd.RideTime )\n",
    "\n",
    "if 'RideInstance' in dfa:\n",
    "    del dfa['RideInstance']\n",
    "dfa.insert(0, 'RideInstance', dfa.RideId.astype(str) + '#' + dfa.RideTime )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = dfa.drop_duplicates('RideInstance', keep='last')\n",
    "dfd = dfd.drop_duplicates('RideInstance', keep='last')\n",
    "dfa.index = dfa.RideInstance\n",
    "dfd.index = dfd.RideInstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.join(dfd, rsuffix='_Departure').RideInstance_Departure.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RideInstance</th>\n",
       "      <th>ObservationTime</th>\n",
       "      <th>RideId</th>\n",
       "      <th>RideTime</th>\n",
       "      <th>DepartureStationCode</th>\n",
       "      <th>DepartureStationUIC</th>\n",
       "      <th>DepartureStationType</th>\n",
       "      <th>TrainId</th>\n",
       "      <th>TrainType</th>\n",
       "      <th>TrainOperator</th>\n",
       "      <th>DestinationStationCode</th>\n",
       "      <th>DestinationStationUIC</th>\n",
       "      <th>DestinationStationType</th>\n",
       "      <th>PlannedArrivalTime</th>\n",
       "      <th>ActualArrivalTime</th>\n",
       "      <th>PlannedArrivalPlatform</th>\n",
       "      <th>PlannedArrivalPlatformSuffix</th>\n",
       "      <th>ActualArrivalPlatform</th>\n",
       "      <th>ActualArrivalPlatformSuffix</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RideInstance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RideInstance, ObservationTime, RideId, RideTime, DepartureStationCode, DepartureStationUIC, DepartureStationType, TrainId, TrainType, TrainOperator, DestinationStationCode, DestinationStationUIC, DestinationStationType, PlannedArrivalTime, ActualArrivalTime, PlannedArrivalPlatform, PlannedArrivalPlatformSuffix, ActualArrivalPlatform, ActualArrivalPlatformSuffix]\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.loc[dfa.RideTime != dfa.PlannedArrivalTime]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfd[['RideId','PlannedDepartureTime', 'ActualDepartureTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd.ChangeType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['PlannedArrivalTime', 'ActualArrivalTime', 'PlannedArrivalPlatform', 'ActualArrivalPlatform']] = dfa[['PlannedArrivalTime', 'ActualArrivalTime', 'PlannedArrivalPlatform', 'ActualArrivalPlatform']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsrk1mUwqnCM",
    "outputId": "36854ebe-07cb-4ecd-b9ec-d9823bfaeffa"
   },
   "outputs": [],
   "source": [
    "# you can laod the files again in \n",
    "df_july = pd.read_csv('../data/july.csv.zip')\n",
    "df_august = pd.read_csv('../data/august.csv.zip')\n",
    "df_september = pd.read_csv('../data/september.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmkBFh4tqnCQ"
   },
   "outputs": [],
   "source": [
    "# here you merge them into one big dataframe\n",
    "months = [df_july, df_august, df_september]\n",
    "df_months = pd.concat(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXwV3KZFqnCR"
   },
   "outputs": [],
   "source": [
    "# save the big dataframe again\n",
    "df_months.to_csv('../data/july_to_september.csv.zip', \n",
    "                 index=False, \n",
    "                 compression=dict(method='zip', archive_name='july_to_september.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQIa0u97qnCV"
   },
   "outputs": [],
   "source": [
    "# here we filter out only all rides from utrecht to amsterdam and vise versa\n",
    "df_ut_asd = df_months.loc[((df_months['DepartureStationCode'] == 'UT') & \n",
    "               (df_months['PlannedDestinationStationCode'] == 'ASD')) | \n",
    "              ((df_months['DepartureStationCode'] == 'ASD') & \n",
    "               (df_months['PlannedDestinationStationCode'] == 'UT'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2wgSTEfqnCW"
   },
   "outputs": [],
   "source": [
    "# save the reduced dataframe again\n",
    "df_ut_asd.to_csv('../data/july_to_september_utrecht_amsterdam.csv.zip', \n",
    "                 index=False, \n",
    "                 compression=dict(method='zip', archive_name='july_to_september_utrecht_amsterdam.csv'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoLoadingDataToCSVZip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
