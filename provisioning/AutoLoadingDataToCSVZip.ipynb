{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KPi4bhpBqn8x"
   },
   "source": [
    "# Download this file on your local computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GrURFcNuV_DV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uXxXvIJ6qnCG"
   },
   "outputs": [],
   "source": [
    "def extract_station_info(data, node, prefix):\n",
    "  if node:\n",
    "    data[prefix + 'Code'].append(node.find('./ns2:StationCode', ns).text)\n",
    "    data[prefix + 'UIC'].append(int(node.find('./ns2:UICCode', ns).text))\n",
    "    data[prefix + 'Type'].append(int(node.find('./ns2:Type', ns).text))\n",
    "  else:\n",
    "    data[prefix + 'Code'].append(np.NaN)\n",
    "    data[prefix + 'UIC'].append(np.NaN)\n",
    "    data[prefix + 'Type'].append(np.NaN)\n",
    "\n",
    "def parse_timestamp(date_string):\n",
    "  return datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "def encode_list(nodes, sufix):\n",
    "  UIC_codes = [node.find(sufix, ns).text for node in nodes]\n",
    "  return ';'.join(UIC_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "v7rUsNBxbJVS"
   },
   "outputs": [],
   "source": [
    "# namespace of the xml object\n",
    "ns={\n",
    "    'ns1d': 'urn:ndov:cdm:trein:reisinformatie:messages:5',\n",
    "    'ns1a': 'urn:ndov:cdm:trein:reisinformatie:messages:dynamischeaankomststaat:1',\n",
    "    'ns2': 'urn:ndov:cdm:trein:reisinformatie:data:4',\n",
    "}\n",
    "\n",
    "# dictionary that will save the data while loading it in\n",
    "def arrival_data_template():\n",
    "\n",
    "    return {\n",
    "        'ObservationTime': [],\n",
    "\n",
    "        # Ride\n",
    "        'RideId':[],\n",
    "        'RideTime': [],\n",
    "\n",
    "        # Departure station\n",
    "        'DepartureStationCode': [],\n",
    "        'DepartureStationUIC': [],\n",
    "        'DepartureStationType': [],\n",
    "\n",
    "        # Train\n",
    "        'TrainId': [],\n",
    "        'TrainType': [],\n",
    "        'TrainOperator': [],\n",
    "\n",
    "        # Actual destination\n",
    "        'DestinationStationCode': [],\n",
    "        'DestinationStationUIC': [],\n",
    "        'DestinationStationType': [],\n",
    "\n",
    "        # Arrival times\n",
    "        'PlannedArrivalTime': [],\n",
    "        'ActualArrivalTime': [],\n",
    "\n",
    "        # Arrival platform\n",
    "        'PlannedArrivalPlatform': [],\n",
    "        'PlannedArrivalPlatformSuffix': [],\n",
    "        'ActualArrivalPlatform': [],\n",
    "        'ActualArrivalPlatformSuffix': [],\n",
    "\n",
    "#         # Departure platforms\n",
    "#         'PlannedDeparturePlatform': [],\n",
    "#         'ActualDeparturePlatform': [],\n",
    "\n",
    "#         # Stop stations\n",
    "#         'PlannedStopStations': [],\n",
    "#         'ActualStopStations': [],\n",
    "\n",
    "#         # Matirial type\n",
    "#         'MaterialType': [],\n",
    "#         'MaterialDesignation': [],\n",
    "#         'MaterialLength': [],\n",
    "\n",
    "#         'ChangeType': [],\n",
    "\n",
    "    }\n",
    "\n",
    "def departure_data_template():\n",
    "    return {\n",
    "    'ObservationTime': [],\n",
    "\n",
    "    # Ride\n",
    "    'RideId':[],\n",
    "    'RideTime': [],\n",
    "\n",
    "    # Departure station\n",
    "    'DepartureStationCode': [],\n",
    "    'DepartureStationUIC': [],\n",
    "    'DepartureStationType': [],\n",
    "\n",
    "    # Train\n",
    "    'TrainId': [],\n",
    "    'TrainType': [],\n",
    "    'TrainOperator': [],\n",
    "\n",
    "    # Actual destination\n",
    "    'DestinationStationCode': [],\n",
    "    'DestinationStationUIC': [],\n",
    "    'DestinationStationType': [],\n",
    "\n",
    "    # Departure times\n",
    "    'PlannedDepartureTime': [],\n",
    "    'ActualDepartureTime': [],\n",
    "\n",
    "    # Departure platform\n",
    "    'PlannedDeparturePlatform': [],\n",
    "    'PlannedDeparturePlatformSuffix': [],\n",
    "    'ActualDeparturePlatform': [],\n",
    "    'ActualDeparturePlatformSuffix': [],\n",
    "\n",
    "    # Departure platforms\n",
    "    'PlannedDeparturePlatform': [],\n",
    "    'ActualDeparturePlatform': [],\n",
    "\n",
    "    # Stop stations\n",
    "    'PlannedStopStations': [],\n",
    "    'ActualStopStations': [],\n",
    "\n",
    "    # Matirial type\n",
    "    'MaterialType': [],\n",
    "    'MaterialDesignation': [],\n",
    "    'MaterialLength': [],\n",
    "    \n",
    "    'HasChange': [],\n",
    "    'ChangeType': [],\n",
    "\n",
    "}\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvV614tzWEv_",
    "outputId": "c89cfc93-570a-48bd-f26b-80377ea1c1f3",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "das_tag = b'ReisInformatieProductDAS'\n",
    "# station_amsterdam = b'<ns2:RitStation><ns2:StationCode>ASD</ns2:StationCode>'\n",
    "# station_utrecht = b'<ns2:RitStation><ns2:StationCode>UT</ns2:StationCode>'\n",
    "station_amsterdam = b'<ns2:StationCode>ASD</ns2:StationCode>'\n",
    "station_utrecht = b'<ns2:StationCode>UT</ns2:StationCode>'\n",
    "source_amsterdam = b'<ns2:TreinHerkomst InfoStatus=\"\"Gepland\"\"><ns2:StationCode>ASD</ns2:StationCode'\n",
    "source_utrecht = b'<ns2:TreinHerkomst InfoStatus=\"\"Gepland\"\"><ns2:StationCode>UT</ns2:StationCode>'\n",
    "destination_amsterdam = b'<ns2:TreinEindBestemming InfoStatus=\"\"Gepland\"\"><ns2:StationCode>AMS</ns2:StationCode>'\n",
    "destination_utrecht = b'<ns2:TreinEindBestemming InfoStatus=\"\"Gepland\"\"><ns2:StationCode>UT</ns2:StationCode>'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tag(name):\n",
    "    opening = b'<'+name+b'>'\n",
    "    closing = b'</'+name+b'>'\n",
    "    return opening, closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019-01-01' '2019-01-02' '2019-01-03' '2019-01-04' '2019-01-05'\n",
      " '2019-01-06' '2019-01-07' '2019-01-08' '2019-01-09' '2019-01-10'\n",
      " '2019-01-11' '2019-01-12' '2019-01-13' '2019-01-14' '2019-01-15'\n",
      " '2019-01-16' '2019-01-17' '2019-01-18' '2019-01-19' '2019-01-20'\n",
      " '2019-01-21' '2019-01-22' '2019-01-23' '2019-01-24' '2019-01-25'\n",
      " '2019-01-26' '2019-01-27' '2019-01-28' '2019-01-29' '2019-01-30'\n",
      " '2019-01-31' '2019-02-01' '2019-02-02' '2019-02-03' '2019-02-04'\n",
      " '2019-02-05' '2019-02-06' '2019-02-07' '2019-02-08' '2019-02-09'\n",
      " '2019-02-10' '2019-02-11' '2019-02-12' '2019-02-13' '2019-02-14'\n",
      " '2019-02-15' '2019-02-16' '2019-02-17' '2019-02-18' '2019-02-19'\n",
      " '2019-02-20' '2019-02-21' '2019-02-22' '2019-02-23' '2019-02-24'\n",
      " '2019-02-25' '2019-02-26' '2019-02-27' '2019-02-28' '2019-03-01'\n",
      " '2019-03-02' '2019-03-03' '2019-03-04' '2019-03-05' '2019-03-06'\n",
      " '2019-03-07' '2019-03-08' '2019-03-09' '2019-03-10' '2019-03-11'\n",
      " '2019-03-12' '2019-03-13' '2019-03-14' '2019-03-15' '2019-03-16'\n",
      " '2019-03-17' '2019-03-18' '2019-03-19' '2019-03-20' '2019-03-21'\n",
      " '2019-03-22' '2019-03-23' '2019-03-24' '2019-03-25' '2019-03-26'\n",
      " '2019-03-27' '2019-03-28' '2019-03-29' '2019-03-30' '2019-03-31'\n",
      " '2019-04-01' '2019-04-02' '2019-04-03' '2019-04-04' '2019-04-05'\n",
      " '2019-04-06' '2019-04-07' '2019-04-08' '2019-04-09' '2019-04-10'\n",
      " '2019-04-11' '2019-04-12' '2019-04-13' '2019-04-14' '2019-04-15'\n",
      " '2019-04-16' '2019-04-17' '2019-04-18' '2019-04-19' '2019-04-20'\n",
      " '2019-04-21' '2019-04-22' '2019-04-23' '2019-04-24' '2019-04-25'\n",
      " '2019-04-26' '2019-04-27' '2019-04-28' '2019-04-29' '2019-04-30'\n",
      " '2019-05-01' '2019-05-02' '2019-05-03' '2019-05-04' '2019-05-05'\n",
      " '2019-05-06' '2019-05-07' '2019-05-08' '2019-05-09' '2019-05-10'\n",
      " '2019-05-11' '2019-05-12' '2019-05-13' '2019-05-14' '2019-05-15'\n",
      " '2019-05-16' '2019-05-17' '2019-05-18' '2019-05-19' '2019-05-20'\n",
      " '2019-05-21' '2019-05-22' '2019-05-23' '2019-05-24' '2019-05-25'\n",
      " '2019-05-26' '2019-05-27' '2019-05-28' '2019-05-29' '2019-05-30'\n",
      " '2019-05-31' '2019-06-01' '2019-06-02' '2019-06-03' '2019-06-04'\n",
      " '2019-06-05' '2019-06-06' '2019-06-07' '2019-06-08' '2019-06-09'\n",
      " '2019-06-10' '2019-06-11' '2019-06-12' '2019-06-13' '2019-06-14'\n",
      " '2019-06-15' '2019-06-16' '2019-06-17' '2019-06-18' '2019-06-19'\n",
      " '2019-06-20' '2019-06-21' '2019-06-22' '2019-06-23' '2019-06-24'\n",
      " '2019-06-25' '2019-06-26' '2019-06-27' '2019-06-28' '2019-06-29'\n",
      " '2019-06-30']\n",
      "downloading:  2019-01-01\n",
      "downloading:  2019-01-02\n",
      "downloading:  2019-01-03\n",
      "downloading:  2019-01-04\n",
      "downloading:  2019-01-05\n",
      "downloading:  2019-01-06\n",
      "downloading:  2019-01-07\n",
      "downloading:  2019-01-08\n",
      "downloading:  2019-01-09\n",
      "downloading:  2019-01-10\n",
      "downloading:  2019-01-11\n",
      "downloading:  2019-01-12\n",
      "downloading:  2019-01-13\n",
      "downloading:  2019-01-14\n",
      "downloading:  2019-01-15\n",
      "downloading:  2019-01-16\n",
      "downloading:  2019-01-17\n",
      "downloading:  2019-01-18\n",
      "downloading:  2019-01-19\n",
      "downloading:  2019-01-20\n",
      "downloading:  2019-01-21\n",
      "downloading:  2019-01-22\n",
      "downloading:  2019-01-23\n",
      "downloading:  2019-01-24\n",
      "downloading:  2019-01-25\n",
      "downloading:  2019-01-26\n",
      "downloading:  2019-01-27\n",
      "downloading:  2019-01-28\n",
      "downloading:  2019-01-29\n",
      "downloading:  2019-01-30\n",
      "downloading:  2019-01-31\n",
      "downloading:  2019-02-01\n",
      "downloading:  2019-02-02\n",
      "downloading:  2019-02-03\n",
      "downloading:  2019-02-04\n",
      "downloading:  2019-02-05\n",
      "downloading:  2019-02-06\n",
      "downloading:  2019-02-07\n",
      "downloading:  2019-02-08\n",
      "downloading:  2019-02-09\n",
      "downloading:  2019-02-10\n",
      "downloading:  2019-02-11\n",
      "downloading:  2019-02-12\n",
      "downloading:  2019-02-13\n",
      "downloading:  2019-02-14\n",
      "downloading:  2019-02-15\n",
      "downloading:  2019-02-16\n",
      "downloading:  2019-02-17\n",
      "downloading:  2019-02-18\n",
      "downloading:  2019-02-19\n",
      "downloading:  2019-02-20\n",
      "downloading:  2019-02-21\n",
      "downloading:  2019-02-22\n",
      "downloading:  2019-02-23\n",
      "downloading:  2019-02-24\n",
      "downloading:  2019-02-25\n",
      "downloading:  2019-02-26\n",
      "downloading:  2019-02-27\n",
      "downloading:  2019-02-28\n",
      "downloading:  2019-03-01\n",
      "downloading:  2019-03-02\n",
      "downloading:  2019-03-03\n",
      "downloading:  2019-03-04\n",
      "downloading:  2019-03-05\n",
      "downloading:  2019-03-06\n",
      "downloading:  2019-03-07\n",
      "downloading:  2019-03-08\n",
      "downloading:  2019-03-09\n",
      "downloading:  2019-03-10\n",
      "downloading:  2019-03-11\n",
      "downloading:  2019-03-12\n",
      "downloading:  2019-03-13\n",
      "downloading:  2019-03-14\n",
      "downloading:  2019-03-15\n",
      "downloading:  2019-03-16\n",
      "downloading:  2019-03-17\n",
      "downloading:  2019-03-18\n",
      "downloading:  2019-03-19\n",
      "downloading:  2019-03-20\n",
      "downloading:  2019-03-21\n",
      "downloading:  2019-03-22\n",
      "downloading:  2019-03-23\n",
      "downloading:  2019-03-24\n",
      "downloading:  2019-03-25\n",
      "downloading:  2019-03-26\n",
      "downloading:  2019-03-27\n",
      "downloading:  2019-03-28\n",
      "downloading:  2019-03-29\n",
      "downloading:  2019-03-30\n",
      "downloading:  2019-03-31\n",
      "downloading:  2019-04-01\n",
      "downloading:  2019-04-02\n",
      "downloading:  2019-04-03\n",
      "downloading:  2019-04-04\n",
      "downloading:  2019-04-05\n",
      "downloading:  2019-04-06\n",
      "downloading:  2019-04-07\n",
      "downloading:  2019-04-08\n",
      "downloading:  2019-04-09\n",
      "downloading:  2019-04-10\n",
      "downloading:  2019-04-11\n",
      "downloading:  2019-04-12\n",
      "downloading:  2019-04-13\n",
      "downloading:  2019-04-14\n",
      "downloading:  2019-04-15\n",
      "downloading:  2019-04-16\n",
      "downloading:  2019-04-17\n",
      "downloading:  2019-04-18\n",
      "downloading:  2019-04-19\n",
      "downloading:  2019-04-20\n",
      "downloading:  2019-04-21\n",
      "downloading:  2019-04-22\n",
      "downloading:  2019-04-23\n",
      "downloading:  2019-04-24\n",
      "downloading:  2019-04-25\n",
      "downloading:  2019-04-26\n",
      "downloading:  2019-04-27\n",
      "downloading:  2019-04-28\n",
      "downloading:  2019-04-29\n",
      "downloading:  2019-04-30\n",
      "downloading:  2019-05-01\n",
      "downloading:  2019-05-02\n",
      "downloading:  2019-05-03\n",
      "downloading:  2019-05-04\n",
      "downloading:  2019-05-05\n",
      "downloading:  2019-05-06\n",
      "downloading:  2019-05-07\n",
      "downloading:  2019-05-08\n",
      "downloading:  2019-05-09\n",
      "downloading:  2019-05-10\n",
      "downloading:  2019-05-11\n",
      "downloading:  2019-05-12\n",
      "downloading:  2019-05-13\n",
      "downloading:  2019-05-14\n",
      "downloading:  2019-05-15\n",
      "downloading:  2019-05-16\n",
      "downloading:  2019-05-17\n",
      "downloading:  2019-05-18\n",
      "downloading:  2019-05-19\n",
      "downloading:  2019-05-20\n",
      "downloading:  2019-05-21\n",
      "downloading:  2019-05-22\n",
      "downloading:  2019-05-23\n",
      "downloading:  2019-05-24\n",
      "downloading:  2019-05-25\n",
      "downloading:  2019-05-26\n",
      "downloading:  2019-05-27\n",
      "downloading:  2019-05-28\n",
      "downloading:  2019-05-29\n",
      "downloading:  2019-05-30\n",
      "downloading:  2019-05-31\n",
      "downloading:  2019-06-01\n",
      "downloading:  2019-06-02\n",
      "downloading:  2019-06-03\n",
      "downloading:  2019-06-04\n",
      "downloading:  2019-06-05\n",
      "downloading:  2019-06-06\n",
      "downloading:  2019-06-07\n",
      "downloading:  2019-06-08\n",
      "downloading:  2019-06-09\n",
      "downloading:  2019-06-10\n",
      "downloading:  2019-06-11\n",
      "downloading:  2019-06-12\n",
      "downloading:  2019-06-13\n",
      "downloading:  2019-06-14\n",
      "downloading:  2019-06-15\n",
      "downloading:  2019-06-16\n",
      "downloading:  2019-06-17\n",
      "downloading:  2019-06-18\n",
      "downloading:  2019-06-19\n",
      "downloading:  2019-06-20\n",
      "downloading:  2019-06-21\n",
      "downloading:  2019-06-22\n",
      "downloading:  2019-06-23\n",
      "downloading:  2019-06-24\n",
      "downloading:  2019-06-25\n",
      "downloading:  2019-06-26\n",
      "downloading:  2019-06-27\n",
      "downloading:  2019-06-28\n",
      "downloading:  2019-06-29\n",
      "downloading:  2019-06-30\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import lzma\n",
    "\n",
    "arrival_lines = []\n",
    "departure_lines = []\n",
    "temp_lines = {\n",
    "    'Date': [],\n",
    "    'RideId': [],\n",
    "    'TrainId': [],\n",
    "}\n",
    "\n",
    "parsing_days = pd.date_range(start='2019/1/1', end='2019/6/30').strftime('%Y-%m-%d').values\n",
    "print(parsing_days)\n",
    "\n",
    "for day in parsing_days:\n",
    "    print('downloading: ',day) \n",
    "    url = f'https://trein.fwrite.org/AMS-Aurora-archive/{day[:7]}/DVSPPV_{day}.csv.xz'\n",
    "\n",
    "    req = requests.get(url, stream=True)\n",
    "    with lzma.LZMAFile(req.raw) as file:\n",
    "        for line in file:\n",
    "            # check if this is related to arrivals\n",
    "            if das_tag in line:\n",
    "                # check if the data includes amsterdam and utrecht\n",
    "                if (station_amsterdam in line) and (station_utrecht in line):     \n",
    "                    for tag_name in [b'ns2:RitDatum', b'ns2:RitId', b'ns2:TreinNummer']:\n",
    "                        # get tag and index\n",
    "                        tags =  construct_tag(tag_name)\n",
    "                        start = line.index(tags[0])\n",
    "                        end = line.index(tags[1])\n",
    "                        # set the start to the end of the start string\n",
    "                        start += len(tags[0])\n",
    "                        # get the text we need\n",
    "                        text = line[start:end]\n",
    "                        text = text.decode('utf-8')\n",
    "                        # add the data to coresponding column\n",
    "                        if tag_name == b'ns2:RitDatum':\n",
    "                            temp_lines['Date'].append(text)\n",
    "                        if tag_name == b'ns2:RitId':\n",
    "                            temp_lines['RideId'].append(text)\n",
    "                        if tag_name == b'ns2:TreinNummer':\n",
    "                            temp_lines['TrainId'].append(text)\n",
    "df = pd.DataFrame(temp_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188666, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RideId</th>\n",
       "      <th>TrainId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1405</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1402</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1405</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1405</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1405</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date RideId TrainId\n",
       "0  2018-12-31   1405    1405\n",
       "1  2018-12-31   1402    1402\n",
       "2  2018-12-31   1405    1405\n",
       "3  2018-12-31   1405    1405\n",
       "4  2018-12-31   1405    1405"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(['Date', 'RideId'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46399, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>RideId</th>\n",
       "      <th>TrainId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1405</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1402</td>\n",
       "      <td>1402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1409</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1406</td>\n",
       "      <td>1406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1413</td>\n",
       "      <td>1413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1410</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1417</td>\n",
       "      <td>1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1414</td>\n",
       "      <td>1414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1421</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1418</td>\n",
       "      <td>1418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1425</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>1422</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3016</td>\n",
       "      <td>3016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3023</td>\n",
       "      <td>3023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3018</td>\n",
       "      <td>3018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2925</td>\n",
       "      <td>2925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3025</td>\n",
       "      <td>3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3020</td>\n",
       "      <td>3020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2927</td>\n",
       "      <td>2927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3027</td>\n",
       "      <td>3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2922</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3022</td>\n",
       "      <td>3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2929</td>\n",
       "      <td>2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3029</td>\n",
       "      <td>3029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2924</td>\n",
       "      <td>2924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3024</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2931</td>\n",
       "      <td>2931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2926</td>\n",
       "      <td>2926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3031</td>\n",
       "      <td>3031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3026</td>\n",
       "      <td>3026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2933</td>\n",
       "      <td>2933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3033</td>\n",
       "      <td>3033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2928</td>\n",
       "      <td>2928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3028</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2935</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3035</td>\n",
       "      <td>3035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>2930</td>\n",
       "      <td>2930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>837</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3030</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3937</td>\n",
       "      <td>3937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3932</td>\n",
       "      <td>3932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3037</td>\n",
       "      <td>3037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>832</td>\n",
       "      <td>832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>839</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3032</td>\n",
       "      <td>3032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3939</td>\n",
       "      <td>3939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3934</td>\n",
       "      <td>3934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>3039</td>\n",
       "      <td>3039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date RideId TrainId\n",
       "0    2018-12-31   1405    1405\n",
       "1    2018-12-31   1402    1402\n",
       "9    2019-01-01   1409    1409\n",
       "10   2018-12-31   1406    1406\n",
       "26   2019-01-01   1413    1413\n",
       "32   2019-01-01   1410    1410\n",
       "56   2019-01-01   1417    1417\n",
       "61   2019-01-01   1414    1414\n",
       "76   2019-01-01   1421    1421\n",
       "82   2019-01-01   1418    1418\n",
       "103  2019-01-01   1425    1425\n",
       "116  2019-01-01   1422    1422\n",
       "135  2019-01-01   3016    3016\n",
       "147  2019-01-01   3023    3023\n",
       "151  2019-01-01   3018    3018\n",
       "152  2019-01-01   2925    2925\n",
       "160  2019-01-01   3025    3025\n",
       "166  2019-01-01   3020    3020\n",
       "169  2019-01-01   2927    2927\n",
       "184  2019-01-01   3027    3027\n",
       "186  2019-01-01   2922    2922\n",
       "199  2019-01-01   3022    3022\n",
       "201  2019-01-01   2929    2929\n",
       "246  2019-01-01   3029    3029\n",
       "249  2019-01-01   2924    2924\n",
       "275  2019-01-01   3024    3024\n",
       "287  2019-01-01   2931    2931\n",
       "334  2019-01-01   2926    2926\n",
       "337  2019-01-01   3031    3031\n",
       "410  2019-01-01   3026    3026\n",
       "434  2019-01-01   2933    2933\n",
       "495  2019-01-01   3033    3033\n",
       "503  2019-01-01   2928    2928\n",
       "548  2019-01-01   3028    3028\n",
       "559  2019-01-01   2935    2935\n",
       "617  2019-01-01   3035    3035\n",
       "628  2019-01-01   2930    2930\n",
       "664  2019-01-01    837     837\n",
       "680  2019-01-01    123     123\n",
       "688  2019-01-01   3030    3030\n",
       "718  2019-01-01   3937    3937\n",
       "729  2019-01-01   3932    3932\n",
       "760  2019-01-01   3037    3037\n",
       "767  2019-01-01    832     832\n",
       "779  2019-01-01    220     220\n",
       "799  2019-01-01    839     839\n",
       "813  2019-01-01   3032    3032\n",
       "831  2019-01-01   3939    3939\n",
       "853  2019-01-01   3934    3934\n",
       "881  2019-01-01   3039    3039"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('../assets/data/2019-UT-ASD-Full/2019-01-01--2019-06-30-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4911"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lzma\n",
    "\n",
    "arrival_lines = []\n",
    "departure_lines = []\n",
    "\n",
    "parsing_days = pd.date_range(start='2019/12/1', end='2019/12/31').strftime('%Y-%m-%d').values\n",
    "print(parsing_days)\n",
    "\n",
    "for day in parsing_days:\n",
    "    print('downloading: ',day) \n",
    "    url = f'https://trein.fwrite.org/AMS-Aurora-archive/{day[:7]}/DVSPPV_{day}.csv.xz'\n",
    "\n",
    "    req = requests.get(url, stream=True)\n",
    "\n",
    "    with lzma.LZMAFile(req.raw) as file:\n",
    "        for line in file:\n",
    "            if (source_utrecht in line and station_amsterdam in line) or (source_amsterdam in line and station_utrecht in line) :\n",
    "                arrival_lines.append(line)\n",
    "            if (station_amsterdam in line and destination_utrecht in line) or (station_utrecht in line and destination_amsterdam in line) :\n",
    "                departure_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "df_arrivals = pd.read_csv(StringIO(b'\\n'.join(arrival_lines).decode('utf-8')), header=None, names=['date', 'xml_obj', 'uuid'])\n",
    "df_departures = pd.read_csv(StringIO(b'\\n'.join(departure_lines).decode('utf-8')), header=None, names=['date', 'xml_obj', 'uuid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2534, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_arrivals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_departures' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-859afafa5faf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_departures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../assets/data/2019 UT-ASD/2019-12-01--2019-12-31_departures.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_arrivals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../assets/data/2019 UT-ASD/2019-12-01--2019-12-31_arrivals.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_departures' is not defined"
     ]
    }
   ],
   "source": [
    "df_departures.to_csv('../assets/data/2019 UT-ASD/2019-12-01--2019-12-31_departures.csv', index=None)\n",
    "df_arrivals.to_csv('../assets/data/2019 UT-ASD/2019-12-01--2019-12-31_arrivals.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBSuCEgmqnCJ"
   },
   "source": [
    "# Please keep in mind this is memory intensive good approach is to do each month seperately and later merge them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzKgbl6ZWGuj",
    "outputId": "998187e4-fbe1-4305-d4dd-fbbed9ddcc7d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 18)\n"
     ]
    }
   ],
   "source": [
    "arrival_data = arrival_data_template()\n",
    "\n",
    "# loop through every day\n",
    "\n",
    "for root_text, observation_time in df_arrivals[['xml_obj', 'date']].values:  \n",
    "            \n",
    "    arrival_data['ObservationTime'].append(observation_time)\n",
    "\n",
    "    root = ET.fromstring(root_text)\n",
    "\n",
    "    # Ride\n",
    "    ride = root.find('./ns2:ReisInformatieProductDAS/ns2:DynamischeAankomstStaat', ns)\n",
    "\n",
    "    arrival_data['RideId'].append(int(ride.find('./ns2:RitId', ns).text))\n",
    "    arrival_data['RideTime'].append(root.find('./ns2:ReisInformatieProductDAS/ns2:RIPAdministratie/ns2:ReisInformatieTijdstip', ns).text)\n",
    "\n",
    "    # Stations\n",
    "    train = ride.find('./ns2:TreinAankomst', ns)\n",
    "\n",
    "    destinationStation = ride.find('./ns2:RitStation', ns)\n",
    "    departureStation = train.find('./ns2:TreinHerkomst[@InfoStatus=\"Gepland\"]',ns)\n",
    "    \n",
    "    extract_station_info(arrival_data, departureStation, 'DepartureStation')\n",
    "    extract_station_info(arrival_data, destinationStation, 'DestinationStation')\n",
    "\n",
    "    # Arrival times\n",
    "    arrival_data['ActualArrivalTime'].append(train.find('./ns2:AankomstTijd[@InfoStatus=\"Actueel\"]', ns).text)\n",
    "    arrival_data['PlannedArrivalTime'].append(train.find('./ns2:AankomstTijd[@InfoStatus=\"Gepland\"]', ns).text)\n",
    "    \n",
    "    # Train\n",
    "    arrival_data['TrainId'].append(train.find('./ns2:TreinNummer', ns).text)\n",
    "    arrival_data['TrainType'].append(train.find('./ns2:TreinSoort', ns).text)\n",
    "    arrival_data['TrainOperator'].append(train.find('./ns2:Vervoerder', ns).text)\n",
    "\n",
    "    arrival_data['PlannedArrivalPlatform'].append(train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorNummer', ns).text)\n",
    "    suffix = train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorFase', ns)\n",
    "    arrival_data['PlannedArrivalPlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "\n",
    "    arrival_data['ActualArrivalPlatform'].append(train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorNummer', ns).text)\n",
    "    suffix = train.find('./ns2:TreinAankomstSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorFase', ns)\n",
    "    arrival_data['ActualArrivalPlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "    \n",
    "# Convert the dictionary to a dataframe\n",
    "dfa = pd.DataFrame(arrival_data)    \n",
    "print(dfa.shape) # show the file size kinda\n",
    "# # save the file, specify your path and name for the file\n",
    "# df_flat.to_csv('./data/september.csv.zip', \n",
    "#                index=False, \n",
    "#                compression=dict(method='zip', archive_name='january.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 18)\n"
     ]
    }
   ],
   "source": [
    "departure_data = departure_data_template()\n",
    "# Parse records about departures\n",
    "for root_text, observation_time in df_departures[['xml_obj', 'date']].values:  \n",
    "            \n",
    "    departure_data['ObservationTime'].append(observation_time)\n",
    "\n",
    "    root = ET.fromstring(root_text)\n",
    "\n",
    "    # Ride\n",
    "    ride = root.find('./ns2:ReisInformatieProductDVS/ns2:DynamischeVertrekStaat', ns)\n",
    "\n",
    "    departure_data['RideId'].append(int(ride.find('./ns2:RitId', ns).text))\n",
    "    departure_data['RideTime'].append(root.find('./ns2:ReisInformatieProductDVS/ns2:RIPAdministratie/ns2:ReisInformatieTijdstip', ns).text)\n",
    "\n",
    "    # Stations\n",
    "    train = ride.find('./ns2:Trein', ns)\n",
    "\n",
    "    departureStation = ride.find('./ns2:RitStation', ns)\n",
    "    destinationStation = train.find('./ns2:TreinEindBestemming[@InfoStatus=\"Gepland\"]',ns)\n",
    "    \n",
    "    extract_station_info(departure_data, departureStation, 'DepartureStation')\n",
    "    extract_station_info(departure_data, destinationStation, 'DestinationStation')\n",
    "\n",
    "    # Departure times\n",
    "    departure_data['ActualDepartureTime'].append(train.find('./ns2:VertrekTijd[@InfoStatus=\"Actueel\"]', ns).text)\n",
    "    departure_data['PlannedDepartureTime'].append(train.find('./ns2:VertrekTijd[@InfoStatus=\"Gepland\"]', ns).text)\n",
    "    \n",
    "    # Train\n",
    "    departure_data['TrainId'].append(train.find('./ns2:TreinNummer', ns).text)\n",
    "    departure_data['TrainType'].append(train.find('./ns2:TreinSoort', ns).text)\n",
    "    departure_data['TrainOperator'].append(train.find('./ns2:Vervoerder', ns).text)\n",
    "\n",
    "    departure_data['PlannedDeparturePlatform'].append(train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorNummer', ns).text)\n",
    "    suffix = train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Gepland\"]/ns2:SpoorFase', ns)\n",
    "    departure_data['PlannedDeparturePlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "\n",
    "    departure_data['ActualDeparturePlatform'].append(train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorNummer', ns).text)\n",
    "    suffix = train.find('./ns2:TreinVertrekSpoor[@InfoStatus=\"Actueel\"]/ns2:SpoorFase', ns)\n",
    "    departure_data['ActualDeparturePlatformSuffix'].append(None if suffix is None else suffix.text)\n",
    "    \n",
    "    # Stop stations\n",
    "    wagons = train.find('./ns2:TreinVleugel', ns)\n",
    "    if not wagons: print('No wagons, wtf?')\n",
    "    stop_stations = wagons.findall('./ns2:StopStations[@InfoStatus=\"Gepland\"]/ns2:Station', ns)\n",
    "    if not stop_stations: print('No stop_stations, wtf?')\n",
    "\n",
    "    departure_data['PlannedStopStations'].append(encode_list(stop_stations, './ns2:UICCode'))\n",
    "\n",
    "    stop_stations = wagons.findall('./ns2:StopStations[@InfoStatus=\"Actueel\"]/ns2:Station', ns)\n",
    "    departure_data['ActualStopStations'].append(encode_list(stop_stations, './ns2:UICCode'))\n",
    "    if not stop_stations: print('No stop_stations2, wtf?')\n",
    "\n",
    "    # Material\n",
    "    material = wagons.find('./ns2:MaterieelDeelDVS', ns)\n",
    "    if material:\n",
    "        departure_data['MaterialType'].append(material.find('./ns2:MaterieelSoort', ns).text)\n",
    "        departure_data['MaterialDesignation'].append(material.find('./ns2:MaterieelAanduiding', ns).text)\n",
    "        departure_data['MaterialLength'].append(material.find('./ns2:MaterieelLengte', ns).text)\n",
    "    else:\n",
    "        departure_data['MaterialType'].append(np.NaN)\n",
    "        departure_data['MaterialDesignation'].append(np.NaN)\n",
    "        departure_data['MaterialLength'].append(np.NaN)\n",
    "\n",
    "    # Change\n",
    "    changes = root.findall('./ns2:Wijziging', ns)\n",
    "    if changes:\n",
    "        departure_data['HasChange'].append(True)\n",
    "        departure_data['ChangeType'].append(encode_list(changes, './ns2:WijzigingType'))\n",
    "    else:\n",
    "        departure_data['HasChange'].append(False)\n",
    "        departure_data['ChangeType'].append(np.NaN)\n",
    "        \n",
    "dfd = pd.DataFrame(departure_data)  \n",
    "print(dfa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObservationTime</th>\n",
       "      <th>RideId</th>\n",
       "      <th>RideTime</th>\n",
       "      <th>DepartureStationCode</th>\n",
       "      <th>DepartureStationUIC</th>\n",
       "      <th>DepartureStationType</th>\n",
       "      <th>TrainId</th>\n",
       "      <th>TrainType</th>\n",
       "      <th>TrainOperator</th>\n",
       "      <th>DestinationStationCode</th>\n",
       "      <th>DestinationStationUIC</th>\n",
       "      <th>DestinationStationType</th>\n",
       "      <th>PlannedArrivalTime</th>\n",
       "      <th>ActualArrivalTime</th>\n",
       "      <th>PlannedArrivalPlatform</th>\n",
       "      <th>PlannedArrivalPlatformSuffix</th>\n",
       "      <th>ActualArrivalPlatform</th>\n",
       "      <th>ActualArrivalPlatformSuffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2019-03-01 07:23:10.246488+01:00</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>ICE International</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2019-03-01 08:31:34.442566+01:00</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>ICE International</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>2019-03-01T07:34:21.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2019-03-01 08:32:04.804135+01:00</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>ICE International</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>2019-03-01T07:33:54.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2019-03-01 08:33:26.746973+01:00</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>ICE International</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>2019-03-01T07:33:54.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2019-03-01 08:34:09.156114+01:00</td>\n",
       "      <td>105</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>ICE International</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>8400621</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-03-01T07:33:00.000Z</td>\n",
       "      <td>2019-03-01T07:34:27.000Z</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ObservationTime  RideId                  RideTime  \\\n",
       "49  2019-03-01 07:23:10.246488+01:00     105  2019-03-01T07:33:00.000Z   \n",
       "51  2019-03-01 08:31:34.442566+01:00     105  2019-03-01T07:33:00.000Z   \n",
       "52  2019-03-01 08:32:04.804135+01:00     105  2019-03-01T07:33:00.000Z   \n",
       "53  2019-03-01 08:33:26.746973+01:00     105  2019-03-01T07:33:00.000Z   \n",
       "54  2019-03-01 08:34:09.156114+01:00     105  2019-03-01T07:33:00.000Z   \n",
       "\n",
       "   DepartureStationCode  DepartureStationUIC  DepartureStationType TrainId  \\\n",
       "49                  ASD              8400058                     6     105   \n",
       "51                  ASD              8400058                     6     105   \n",
       "52                  ASD              8400058                     6     105   \n",
       "53                  ASD              8400058                     6     105   \n",
       "54                  ASD              8400058                     6     105   \n",
       "\n",
       "            TrainType TrainOperator DestinationStationCode  \\\n",
       "49  ICE International            NS                     UT   \n",
       "51  ICE International            NS                     UT   \n",
       "52  ICE International            NS                     UT   \n",
       "53  ICE International            NS                     UT   \n",
       "54  ICE International            NS                     UT   \n",
       "\n",
       "    DestinationStationUIC  DestinationStationType        PlannedArrivalTime  \\\n",
       "49                8400621                       6  2019-03-01T07:33:00.000Z   \n",
       "51                8400621                       6  2019-03-01T07:33:00.000Z   \n",
       "52                8400621                       6  2019-03-01T07:33:00.000Z   \n",
       "53                8400621                       6  2019-03-01T07:33:00.000Z   \n",
       "54                8400621                       6  2019-03-01T07:33:00.000Z   \n",
       "\n",
       "           ActualArrivalTime PlannedArrivalPlatform  \\\n",
       "49  2019-03-01T07:33:00.000Z                     18   \n",
       "51  2019-03-01T07:34:21.000Z                     18   \n",
       "52  2019-03-01T07:33:54.000Z                     18   \n",
       "53  2019-03-01T07:33:54.000Z                     18   \n",
       "54  2019-03-01T07:34:27.000Z                     18   \n",
       "\n",
       "   PlannedArrivalPlatformSuffix ActualArrivalPlatform  \\\n",
       "49                         None                    18   \n",
       "51                         None                    18   \n",
       "52                         None                    18   \n",
       "53                         None                    18   \n",
       "54                         None                    18   \n",
       "\n",
       "   ActualArrivalPlatformSuffix  \n",
       "49                        None  \n",
       "51                        None  \n",
       "52                        None  \n",
       "53                        None  \n",
       "54                        None  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.sort_values(['RideId']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ObservationTime</th>\n",
       "      <th>RideId</th>\n",
       "      <th>RideTime</th>\n",
       "      <th>DepartureStationCode</th>\n",
       "      <th>DepartureStationUIC</th>\n",
       "      <th>DepartureStationType</th>\n",
       "      <th>TrainId</th>\n",
       "      <th>TrainType</th>\n",
       "      <th>TrainOperator</th>\n",
       "      <th>DestinationStationCode</th>\n",
       "      <th>...</th>\n",
       "      <th>PlannedDeparturePlatformSuffix</th>\n",
       "      <th>ActualDeparturePlatform</th>\n",
       "      <th>ActualDeparturePlatformSuffix</th>\n",
       "      <th>PlannedStopStations</th>\n",
       "      <th>ActualStopStations</th>\n",
       "      <th>MaterialType</th>\n",
       "      <th>MaterialDesignation</th>\n",
       "      <th>MaterialLength</th>\n",
       "      <th>HasChange</th>\n",
       "      <th>ChangeType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-01 00:09:03.534112+01:00</td>\n",
       "      <td>1402</td>\n",
       "      <td>2019-03-01T00:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1402</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>8400074;8400621</td>\n",
       "      <td>8400074;8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>6</td>\n",
       "      <td>16210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-03-01 01:19:29.990044+01:00</td>\n",
       "      <td>1402</td>\n",
       "      <td>2019-03-01T00:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1402</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>8400074;8400621</td>\n",
       "      <td>8400074;8400621</td>\n",
       "      <td>VIRM</td>\n",
       "      <td>6</td>\n",
       "      <td>16210</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-01 01:09:02.298013+01:00</td>\n",
       "      <td>1406</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1406</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>ICM</td>\n",
       "      <td>3</td>\n",
       "      <td>8060</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-03-01 02:15:38.112751+01:00</td>\n",
       "      <td>1406</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1406</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>ICM</td>\n",
       "      <td>3</td>\n",
       "      <td>8060</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-01 02:19:54.973100+01:00</td>\n",
       "      <td>1406</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "      <td>ASD</td>\n",
       "      <td>8400058</td>\n",
       "      <td>6</td>\n",
       "      <td>1406</td>\n",
       "      <td>Intercity</td>\n",
       "      <td>NS</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>a</td>\n",
       "      <td>11</td>\n",
       "      <td>a</td>\n",
       "      <td>8400621</td>\n",
       "      <td>8400621</td>\n",
       "      <td>ICM</td>\n",
       "      <td>3</td>\n",
       "      <td>8060</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ObservationTime  RideId                  RideTime  \\\n",
       "0  2019-03-01 00:09:03.534112+01:00    1402  2019-03-01T00:19:00.000Z   \n",
       "5  2019-03-01 01:19:29.990044+01:00    1402  2019-03-01T00:19:00.000Z   \n",
       "4  2019-03-01 01:09:02.298013+01:00    1406  2019-03-01T01:19:00.000Z   \n",
       "7  2019-03-01 02:15:38.112751+01:00    1406  2019-03-01T01:19:00.000Z   \n",
       "8  2019-03-01 02:19:54.973100+01:00    1406  2019-03-01T01:19:00.000Z   \n",
       "\n",
       "  DepartureStationCode  DepartureStationUIC  DepartureStationType TrainId  \\\n",
       "0                  ASD              8400058                     6    1402   \n",
       "5                  ASD              8400058                     6    1402   \n",
       "4                  ASD              8400058                     6    1406   \n",
       "7                  ASD              8400058                     6    1406   \n",
       "8                  ASD              8400058                     6    1406   \n",
       "\n",
       "   TrainType TrainOperator DestinationStationCode  ...  \\\n",
       "0  Intercity            NS                     UT  ...   \n",
       "5  Intercity            NS                     UT  ...   \n",
       "4  Intercity            NS                     UT  ...   \n",
       "7  Intercity            NS                     UT  ...   \n",
       "8  Intercity            NS                     UT  ...   \n",
       "\n",
       "   PlannedDeparturePlatformSuffix  ActualDeparturePlatform  \\\n",
       "0                               a                        7   \n",
       "5                               a                        7   \n",
       "4                               a                       11   \n",
       "7                               a                       11   \n",
       "8                               a                       11   \n",
       "\n",
       "  ActualDeparturePlatformSuffix PlannedStopStations ActualStopStations  \\\n",
       "0                             a     8400074;8400621    8400074;8400621   \n",
       "5                             a     8400074;8400621    8400074;8400621   \n",
       "4                             a             8400621            8400621   \n",
       "7                             a             8400621            8400621   \n",
       "8                             a             8400621            8400621   \n",
       "\n",
       "  MaterialType MaterialDesignation MaterialLength HasChange ChangeType  \n",
       "0         VIRM                   6          16210     False        NaN  \n",
       "5         VIRM                   6          16210     False        NaN  \n",
       "4          ICM                   3           8060     False        NaN  \n",
       "7          ICM                   3           8060     False        NaN  \n",
       "8          ICM                   3           8060     False        NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd.sort_values(['RideId']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RideId</th>\n",
       "      <th>PlannedDepartureTime</th>\n",
       "      <th>ActualDepartureTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1402</td>\n",
       "      <td>2019-03-01T00:19:00.000Z</td>\n",
       "      <td>2019-03-01T00:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7393</td>\n",
       "      <td>2019-02-28T23:28:00.000Z</td>\n",
       "      <td>2019-02-28T23:30:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7393</td>\n",
       "      <td>2019-02-28T23:28:00.000Z</td>\n",
       "      <td>2019-02-28T23:30:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7395</td>\n",
       "      <td>2019-02-28T23:57:00.000Z</td>\n",
       "      <td>2019-02-28T23:57:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1406</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1402</td>\n",
       "      <td>2019-03-01T00:19:00.000Z</td>\n",
       "      <td>2019-03-01T00:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1412</td>\n",
       "      <td>2019-03-01T02:19:00.000Z</td>\n",
       "      <td>2019-03-01T02:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1406</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1406</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "      <td>2019-03-01T01:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1414</td>\n",
       "      <td>2019-03-01T03:19:00.000Z</td>\n",
       "      <td>2019-03-01T03:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1412</td>\n",
       "      <td>2019-03-01T02:19:00.000Z</td>\n",
       "      <td>2019-03-01T02:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1412</td>\n",
       "      <td>2019-03-01T02:19:00.000Z</td>\n",
       "      <td>2019-03-01T02:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1418</td>\n",
       "      <td>2019-03-01T04:21:00.000Z</td>\n",
       "      <td>2019-03-01T04:21:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1414</td>\n",
       "      <td>2019-03-01T03:19:00.000Z</td>\n",
       "      <td>2019-03-01T03:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1414</td>\n",
       "      <td>2019-03-01T03:19:00.000Z</td>\n",
       "      <td>2019-03-01T03:19:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1418</td>\n",
       "      <td>2019-03-01T04:21:00.000Z</td>\n",
       "      <td>2019-03-01T04:21:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1418</td>\n",
       "      <td>2019-03-01T04:21:00.000Z</td>\n",
       "      <td>2019-03-01T04:21:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7469</td>\n",
       "      <td>2019-03-01T17:41:00.000Z</td>\n",
       "      <td>2019-03-01T17:41:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7471</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:09:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:09:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:09:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7467</td>\n",
       "      <td>2019-03-01T17:08:00.000Z</td>\n",
       "      <td>2019-03-01T17:09:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7469</td>\n",
       "      <td>2019-03-01T17:41:00.000Z</td>\n",
       "      <td>2019-03-01T17:41:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7469</td>\n",
       "      <td>2019-03-01T17:41:00.000Z</td>\n",
       "      <td>2019-03-01T17:41:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7471</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "      <td>2019-03-01T18:09:27.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7471</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "      <td>2019-03-01T18:10:53.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7471</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "      <td>2019-03-01T18:10:53.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7471</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "      <td>2019-03-01T18:11:06.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7471</td>\n",
       "      <td>2019-03-01T18:08:00.000Z</td>\n",
       "      <td>2019-03-01T18:11:06.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3089</td>\n",
       "      <td>2019-03-01T22:54:00.000Z</td>\n",
       "      <td>2019-03-01T22:54:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7393</td>\n",
       "      <td>2019-03-01T23:28:00.000Z</td>\n",
       "      <td>2019-03-01T23:28:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7395</td>\n",
       "      <td>2019-03-01T23:57:00.000Z</td>\n",
       "      <td>2019-03-01T23:57:00.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3089</td>\n",
       "      <td>2019-03-01T22:54:00.000Z</td>\n",
       "      <td>2019-03-01T22:54:00.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RideId      PlannedDepartureTime       ActualDepartureTime\n",
       "0     1402  2019-03-01T00:19:00.000Z  2019-03-01T00:19:00.000Z\n",
       "1     7393  2019-02-28T23:28:00.000Z  2019-02-28T23:30:00.000Z\n",
       "2     7393  2019-02-28T23:28:00.000Z  2019-02-28T23:30:00.000Z\n",
       "3     7395  2019-02-28T23:57:00.000Z  2019-02-28T23:57:00.000Z\n",
       "4     1406  2019-03-01T01:19:00.000Z  2019-03-01T01:19:00.000Z\n",
       "5     1402  2019-03-01T00:19:00.000Z  2019-03-01T00:19:00.000Z\n",
       "6     1412  2019-03-01T02:19:00.000Z  2019-03-01T02:19:00.000Z\n",
       "7     1406  2019-03-01T01:19:00.000Z  2019-03-01T01:19:00.000Z\n",
       "8     1406  2019-03-01T01:19:00.000Z  2019-03-01T01:19:00.000Z\n",
       "9     1414  2019-03-01T03:19:00.000Z  2019-03-01T03:19:00.000Z\n",
       "10    1412  2019-03-01T02:19:00.000Z  2019-03-01T02:19:00.000Z\n",
       "11    1412  2019-03-01T02:19:00.000Z  2019-03-01T02:19:00.000Z\n",
       "12    1418  2019-03-01T04:21:00.000Z  2019-03-01T04:21:00.000Z\n",
       "13    1414  2019-03-01T03:19:00.000Z  2019-03-01T03:19:00.000Z\n",
       "14    1414  2019-03-01T03:19:00.000Z  2019-03-01T03:19:00.000Z\n",
       "15    1418  2019-03-01T04:21:00.000Z  2019-03-01T04:21:00.000Z\n",
       "16    1418  2019-03-01T04:21:00.000Z  2019-03-01T04:21:00.000Z\n",
       "17    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:08:00.000Z\n",
       "18    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:08:00.000Z\n",
       "19    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:08:00.000Z\n",
       "20    7469  2019-03-01T17:41:00.000Z  2019-03-01T17:41:00.000Z\n",
       "21    7471  2019-03-01T18:08:00.000Z  2019-03-01T18:08:00.000Z\n",
       "22    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:09:43.000Z\n",
       "23    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:09:43.000Z\n",
       "24    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:09:43.000Z\n",
       "25    7467  2019-03-01T17:08:00.000Z  2019-03-01T17:09:43.000Z\n",
       "26    7469  2019-03-01T17:41:00.000Z  2019-03-01T17:41:00.000Z\n",
       "27    7469  2019-03-01T17:41:00.000Z  2019-03-01T17:41:00.000Z\n",
       "28    7471  2019-03-01T18:08:00.000Z  2019-03-01T18:09:27.000Z\n",
       "29    7471  2019-03-01T18:08:00.000Z  2019-03-01T18:10:53.000Z\n",
       "30    7471  2019-03-01T18:08:00.000Z  2019-03-01T18:10:53.000Z\n",
       "31    7471  2019-03-01T18:08:00.000Z  2019-03-01T18:11:06.000Z\n",
       "32    7471  2019-03-01T18:08:00.000Z  2019-03-01T18:11:06.000Z\n",
       "33    3089  2019-03-01T22:54:00.000Z  2019-03-01T22:54:00.000Z\n",
       "34    7393  2019-03-01T23:28:00.000Z  2019-03-01T23:28:00.000Z\n",
       "35    7395  2019-03-01T23:57:00.000Z  2019-03-01T23:57:00.000Z\n",
       "36    3089  2019-03-01T22:54:00.000Z  2019-03-01T22:54:00.000Z"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfd[['RideId','PlannedDepartureTime', 'ActualDepartureTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zsrk1mUwqnCM",
    "outputId": "36854ebe-07cb-4ecd-b9ec-d9823bfaeffa"
   },
   "outputs": [],
   "source": [
    "# you can laod the files again in \n",
    "df_july = pd.read_csv('../data/july.csv.zip')\n",
    "df_august = pd.read_csv('../data/august.csv.zip')\n",
    "df_september = pd.read_csv('../data/september.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmkBFh4tqnCQ"
   },
   "outputs": [],
   "source": [
    "# here you merge them into one big dataframe\n",
    "months = [df_july, df_august, df_september]\n",
    "df_months = pd.concat(months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXwV3KZFqnCR"
   },
   "outputs": [],
   "source": [
    "# save the big dataframe again\n",
    "df_months.to_csv('../data/july_to_september.csv.zip', \n",
    "                 index=False, \n",
    "                 compression=dict(method='zip', archive_name='july_to_september.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQIa0u97qnCV"
   },
   "outputs": [],
   "source": [
    "# here we filter out only all rides from utrecht to amsterdam and vise versa\n",
    "df_ut_asd = df_months.loc[((df_months['DepartureStationCode'] == 'UT') & \n",
    "               (df_months['PlannedDestinationStationCode'] == 'ASD')) | \n",
    "              ((df_months['DepartureStationCode'] == 'ASD') & \n",
    "               (df_months['PlannedDestinationStationCode'] == 'UT'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2wgSTEfqnCW"
   },
   "outputs": [],
   "source": [
    "# save the reduced dataframe again\n",
    "df_ut_asd.to_csv('../data/july_to_september_utrecht_amsterdam.csv.zip', \n",
    "                 index=False, \n",
    "                 compression=dict(method='zip', archive_name='july_to_september_utrecht_amsterdam.csv'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AutoLoadingDataToCSVZip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
